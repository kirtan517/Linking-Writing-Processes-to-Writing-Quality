{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from Functionality import Reduce_numerical_columns,Reduce_text_change,Reduce_event,Reduce_activity,getX_Y,getModel,performCrossValidation,makePredictions,perfromGridSearch,performKfoldScore,Aggregation,ConcatAlongId\n",
    "from sklearn.linear_model import LinearRegression,SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directories Where the data is present\n",
    "train_logs_directory = os.path.join(\"Data\",\"train_logs.csv\")\n",
    "train_scores_directory = os.path.join(\"Data\",\"train_scores.csv\")\n",
    "test_logs_directory = os.path.join(\"Data\",\"test_logs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# following the naming convention that everything related\n",
    "# to train will be followed by train_ and everything followed by test will be followed by test_\n",
    "train_logs_df = pd.read_csv(train_logs_directory)\n",
    "test_logs_df = pd.read_csv(test_logs_directory)\n",
    "train_scores_df = pd.read_csv(train_scores_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_logs_df,train_scores_df,on = \"id\",how = \"inner\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# No null values are present\n",
    "# train_logs_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df[\"up_event\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Highly skewed dataset\n",
    "train_df[\"activity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df[\"activity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text_change\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset between the categorical and numerical values\n",
    "num_attributes = [\"id\",\"event_id\",\"down_time\",\"up_time\",\"action_time\",\"cursor_position\",\"word_count\"]\n",
    "cat_attributes = [\"activity\",\"down_event\",\"up_event\",\"text_change\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processing = ColumnTransformer([\n",
    "    (\"RemoveId\",make_pipeline(Reduce_numerical_columns()),num_attributes),\n",
    "     (\"ValueSum\",make_pipeline(Reduce_text_change()),[\"text_change\"]),\n",
    "    (\"RemoveMove\",make_pipeline(Reduce_activity(),OneHotEncoder(sparse_output=False)),[\"activity\"]),\n",
    "    (\"ReduceUpEvents\",make_pipeline(Reduce_event()),[\"up_event\"]),\n",
    "    # (\"ReduceDownEvents\",make_pipeline(Reduce_event()),[\"down_event\"]),   \n",
    "],\n",
    "    # remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_logs_df,y = getX_Y(train_logs_df,train_scores_df,perform_harmonic_variation=False,aggregation=True)\n",
    "train_processed_numpy = processing.fit_transform(train_logs_df)\n",
    "test_processed_numpy = processing.transform(test_logs_df)\n",
    "train_processed_df = pd.DataFrame(train_processed_numpy,columns=processing.get_feature_names_out())\n",
    "test_processed_df = pd.DataFrame(test_processed_numpy,columns=processing.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_processing = make_pipeline(Aggregation())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Concating the columns \n",
    "train_postprocessed_df = ConcatAlongId(train_processed_df,train_logs_df)\n",
    "test_postprocessed_df = ConcatAlongId(test_processed_df,test_logs_df)\n",
    "\n",
    "# Aggreagating the columns for both train and test\n",
    "train_postprocessed_numpy = post_processing.fit_transform(train_postprocessed_df)\n",
    "train_postprocessed_df = pd.DataFrame(train_postprocessed_numpy,columns=post_processing.get_feature_names_out())\n",
    "test_postprocessed_numpy = post_processing.fit_transform(test_postprocessed_df)\n",
    "test_postprocessed_df = pd.DataFrame(test_postprocessed_numpy,columns=post_processing.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "# Add first model\n",
    "model = RandomForestRegressor(n_estimators=900,      # You can tune this\n",
    "                              max_depth=300,          # You can tune this\n",
    "                              min_samples_split=10,   # You can tune this\n",
    "                              min_samples_leaf=10,    # You can tune this\n",
    "                              max_features='sqrt',   # You can tune this\n",
    "                              bootstrap=True,        # You can tune this\n",
    "                              oob_score=True,        # Monitor OOB score\n",
    "                              random_state=42)\n",
    "models.append(model)\n",
    "\n",
    "# Add second model \n",
    "model = RandomForestRegressor(n_estimators=900,      # You can tune this\n",
    "                              max_depth=300,          # You can tune this\n",
    "                              min_samples_split=10,   # You can tune this\n",
    "                              min_samples_leaf=10,    # You can tune this\n",
    "                              max_features='sqrt',   # You can tune this\n",
    "                              bootstrap=True,        # You can tune this\n",
    "                              oob_score=True,        # Monitor OOB score\n",
    "                              random_state=42)\n",
    "models.append(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i,model in enumerate(models): \n",
    "    results = performCrossValidation(model,train_postprocessed_df,train_logs_df,y,aggregation=True)\n",
    "    results.to_csv(f\"{i}.csv\")\n",
    "    model.fit(train_postprocessed_df,y)\n",
    "    dataset_train = makePredictions(model,train_postprocessed_df,train_logs_df,aggregation=True)\n",
    "    t = mean_squared_error(y,dataset_train)\n",
    "    print(f\"{i} ----------> {t}\")  \n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = performCrossValidation(model,train_postprocessed_df,train_logs_df,y,aggregation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(train_postprocessed_df,y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_train = makePredictions(model,train_postprocessed_df,train_logs_df,aggregation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test = makePredictions(model,test_postprocessed_df,test_logs_df,aggregation=True) "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_squared_error(y,dataset_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For submission\n",
    "dataset_test[\"y_pred\"].to_csv(\"submission.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For Model Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model,params = getModel(\"RandomForestRegressor\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scores = performCrossValidation(model,train_processed_df,train_logs_df,y)\n",
    "model,results = perfromGridSearch(model,params,train_postprocessed_df,train_logs_df,y,results=True,aggregation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.fit(train_processed_df,y)\n",
    "dataset_train = makePredictions(model,train_postprocessed_df,train_logs_df,aggregation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test = makePredictions(model,test_processed_df,test_logs_df,aggregation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_train.to_csv(\"train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_squared_error(dataset_train[\"y_true\"],dataset_train[\"y_pred\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test[\"y_pred\"].to_csv(\"submission.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimize with Optuna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model,params = getModel(\"RandomForestRegressor\",optuna=True,trial=trial)\n",
    "    score = performKfoldScore(model,train_processed_df,train_logs_df,y,k=3,optuna = True,trial = trial)\n",
    "    params[0]['n_jobs']=[-1]\n",
    "    return score\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "    storage = \"sqlite:///linking-writing-process-to-writing-quality.db\",\n",
    "    study_name = \"RandomForest\"\n",
    ")\n",
    "study.optimize(objective, n_trials=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
